---
title: "Lab 3: Student Evaluations of Teaching"
author: "Trycia Vong"
format: 
  html:  
    embed-resources: true
    code-tools: true
    toc: true
editor: source
execute: 
  echo: true
  warning: false
  message: false
---

### The Data

The `teacher_evals` dataset contains student evaluations of teaching (SET) collected from students at a university in Poland. There are SET surveys from students in all fields and all levels of study offered by the university. 

The SET questionnaire that students at this university complete is as follows:

> Evaluation survey of the teaching staff of [university name].
>
> Please complete the following evaluation form, which aims to assess the lecturer’s performance. Only one answer should be indicated for each question. The answers are coded in the following way: 5 - I strongly agree; 4 - I agree; 3 - Neutral; 2 - I don’t agree; 1 - I strongly don’t agree.
>
> Question 1: I learnt a lot during the course. 
>
> Question 2: I think that the knowledge acquired during the course is very useful.
>
> Question 3: The professor used activities to make the class more engaging.
>
> Question 4: If it was possible, I would enroll for a course conducted by this lecturer again. 
>
> Question 5: The classes started on time.
>
> Question 6: The lecturer always used time efficiently.
>
> Question 7: The lecturer delivered the class content in an understandable and efficient way.
>
> Question 8: The lecturer was available when we had doubts.
>
> Question 9. The lecturer treated all students equally regardless of their race, background and ethnicity.


These data are from the end of the winter semester of the 2020-2021 academic year. In the period of data collection, all university  classes were entirely online amid the Covid-19 pandemic. While expected learning outcomes were not changed, the online mode of study could have affected grading policies and could have implications for the data.

**Average SET scores** were combined with many other variables, including:

1. **characteristics of the teacher** (degree, seniority, gender, SET scores in the past 6 semesters).
2. **characteristics of the course** (time of day, day of the week, course type, course breadth, class duration, class size).
3. **percentage of students providing SET feedback.**
4. **course grades** (mean, standard deviation, percentage failed for the current course and previous 6 semesters).

This rich dataset allows us to **investigate many of the biases in student evaluations of teaching** that have been reported in the literature and to formulate new hypotheses.

**1. Load the appropriate R packages and the `teacher_evals` data.**

```{r setup}
# code chunk for loading packages
library(dplyr)
library(knitr)
library(readr)
library(ggplot2)
```

```{r}
# code chunk for importing the data
teacherData <- read_csv(file = "teacher_evals.csv")
```

### Data Inspection + Summary


**2. Provide a brief overview (~4 sentences) of the dataset.**

**Summary**

The data came from Poland university students evaluating a professor from Winter 2020-2021.There are 22 columns and 8015 rows of data of SET (student evaluations of teaching). There is an average of 46.95 responses for each question per professor. And most students have an average grade of 3.962, which is a pretty good grade so maybe that influxes their opinion of the professor.


```{r}
# you may want to use code to answer this question
summary(teacherData)
dim(teacherData)
spec(teacherData)
```

**3. What is the unit of observation (i.e. a single row in the dataset) identified by?**


The unit of observation is a professor and that specific question pertaining to that teacher and the questions rating of all the students and the students' data.

**4. Use *one* `dplyr` pipeline to clean the data by**

 - **renaming the `gender` variable `sex`,**
 - **removing all courses with fewer than 10 students (participants),** 
 - **The `question_no` variable refers to the questions 1-9 in the survey, but weirdly takes the values 901-909. Update `question_no` so that it takes the values 1-9.**
 - **changing data types in whichever way you see fit (e.g., is the instructor ID really a numeric data type?), and** 
 - **only keeping the columns we will use -- `course_id`, `teacher_id`, `question_no`, `no_participants`, `resp_share`, `SET_score_avg`, `percent_failed_cur`, `academic_degree`, `seniority`, and `sex`.**


```{r}
# code chunk for Q4

teacher_evals_clean <- teacherData |>
  rename(sex = gender) |>
  filter(no_participants > 10) |>
  mutate(question_no = question_no - 900) |>
  mutate(teacher_id = as.character(teacher_id)) |>
  select(course_id : SET_score_avg, percent_failed_cur, academic_degree : sex)
  
kable(teacher_evals_clean)

```


**5. How many unique instructors and unique courses are present in the cleaned dataset?**

There are 294 instructors and 921 unique courses in the cleaned dataset.

```{r}
# code chunk for Q5
teacherCount <- teacher_evals_clean |>
  summarize(teacherCount = n_distinct(teacher_id))

kable(teacherCount)

courseCount <- teacher_evals_clean |>
  summarize(courseCount = n_distinct(course_id))

kable(courseCount)

```

**6. One teacher-course combination has some missing values, coded as `NA`. Which instructor has these missing values? Which course? What variable are the missing values in? Your code output should clearly answer this question.**

The instructor with the id "56347" has some missing values. It is the "PAB3SE004PA" course and the missing variable is percent_failed_cur.

```{r}
# code chunk for Q6 https://stackoverflow.com/questions/69720079/filter-dataframe-when-all-columns-are-na-in-dplyr, https://chatgpt.com/share/68019727-e014-8009-b21d-028816e09e49
mysteryTeacher <- teacher_evals_clean |>
  filter(if_any(everything(), ~ is.na(.)))
```

**7. What are the demographics of the instructors in this study? Investigate the variables `academic_degree`, `seniority`, and `sex` and summarize your findings in ~3 complete sentences.**

There are 134 female professors and 160 male professors in this SET study. The average seniority between all teachers is 4.891 years of teaching. Out of the 294 professors, 168 have doctorates, 75 have a masters, 43 have no degree and 8 are just professors. 

```{r}
# code chunk for Q7
teacher_evals_clean |>
  select(teacher_id, academic_degree, seniority, sex) |>
  distinct(teacher_id, .keep_all = TRUE) |>
  count(sex) |>
  kable()

teacher_evals_clean |>
  select(teacher_id, academic_degree, seniority, sex) |>
  distinct(teacher_id, .keep_all = TRUE) |>
  summary() |>
  kable()

teacher_evals_clean |>
  select(teacher_id, academic_degree, seniority, sex) |>
  distinct(teacher_id, .keep_all = TRUE) |>
  count(academic_degree) |>
  kable()

``` 


**8. Each course seems to have used a different subset of the 9 evaluation questions. How many teacher-course combinations asked all 9 questions?**

48 teacher-course combinations asked all 9 questions.

```{r}
# code chunk for Q8, https://chatgpt.com/share/6802e159-f878-8009-9ce2-d088c93fe4d5

teacher_evals_clean |>
  group_by(course_id, teacher_id) |>
  filter(n_distinct(question_no) == 9) |>
  count(course_id, teacher_id) |>
  kable()
```


## Rate my Professor

**9. Which instructor(s) had the lowest average rating for Question 1 ("I learnt a lot during the course.") *across all their courses* (i.e. you should be looking at the mean of the `SET_score_avg` variable across courses for each instructor)? Include the number of courses the instructor(s) taught in your output**

**a. Sketch a game plan and include the image below.**

![](gameplan.png)

**b. Implement/code your game plan**

```{r}
# code chunk for Q9 https://chatgpt.com/share/6802e159-f878-8009-9ce2-d088c93fe4d5
teacher_evals_clean |>
  filter(question_no == 1) |>
  group_by(teacher_id) |>
  summarise(avg_SET_score_all_courses = mean(SET_score_avg),
            number_of_courses = n_distinct(course_id)) |>
  # arrange(desc(avg_SET_score_all_courses))
  
  slice_min(order_by = avg_SET_score_all_courses) |>
  kable()
  
```

**10. Which instructor(s), who had *at least five* courses reviewed in the data, had the highest average rating for Question 1 (I learnt a lot during the course.) across all their courses?**

```{r}
# code chunk for Q10
teacher_evals_clean |>
  filter(question_no == 1) |>
  group_by(teacher_id) |>
  summarise(avg_SET_score_all_courses = mean(SET_score_avg),
            number_of_courses = n_distinct(course_id)) |>
  filter(number_of_courses > 4) |>
  slice_max(order_by = avg_SET_score_all_courses) |>
  kable()
```


**11. Which instructor(s) with either a doctorate or professor degree had the highest and lowest average percent of students responding to the evaluation across all their courses? Include how many years the instructor had worked (seniority) and their sex in your output. You can use two pipelines to answer these questions.**


```{r}
# code chunk for Q11
teacher_evals_clean |>
  filter(academic_degree == "dr" | academic_degree == "prof") |>
  group_by(teacher_id, seniority, sex) |>
  summarise(avg_response_all_courses = mean(resp_share)) |>
  ungroup() |>
  slice_max(order_by = avg_response_all_courses) |>
  kable()

teacher_evals_clean |>
  filter(academic_degree == "dr" | academic_degree == "prof") |>
  group_by(teacher_id, seniority, sex) |>
  summarise(avg_response_all_courses = mean(resp_share)) |>
  ungroup() |>
  slice_min(order_by = avg_response_all_courses) |>
  kable()
```

## Chi-Square Test of Independence

Let’s compare the level of SET ratings for *Question 3* (The professor used activities to make the class more engaging.) between senior instructors and junior instructors.

**12. Create a new dataset `teacher_evals_compare` that accomplishes the following with one `dplyr` pipeline:** 

1. **includes responses for Question 3 only,**
2. **creates a new variable called `set_level` that is “excellent” if the `SET_score_avg` is 4 or higher (inclusive) and “standard” otherwise,**
3. **creates a new variable called `sen_level` that is “junior” if the instructor has been teaching for 4 years or less (inclusive), “senior” if between 5-8 years (inclusive), and "very senior" if more than 8 years**
4. **contains only the variables we are interested in – `course_id`, `set_level`, and `sen_level`.**


```{r}
# code chunk for Q12, seems weird skipping out years 4-5 
teacher_evals_compare <- teacher_evals_clean |>
  filter(question_no == 3) |>
  mutate(set_level = case_when(SET_score_avg >= 4 ~ "excellent",
                               TRUE               ~ "standard")) |>
  mutate(sen_level = case_when(seniority <= 4 ~ "junior",
                               seniority > 8  ~ "very senior",
                               (seniority >= 5 & seniority <= 8) ~ "senior",
                               TRUE               ~ "NEITHER")) |>
  select(course_id, set_level, sen_level)
  kable(teacher_evals_compare)
  
  
```

**13. Using the new dataset and your `ggplot2` skills, recreate the filled bar plot shown in the lab instructions online.**


```{r}
# code chunk for Q13, https://www.sthda.com/english/wiki/ggplot2-colors-how-to-change-colors-automatically-and-manually https://chatgpt.com/share/6802fa42-6ba8-8009-bf93-998a9d554bf1, https://stackoverflow.com/questions/59008974/why-is-stat-identity-necessary-in-geom-bar-in-ggplot, https://stackoverflow.com/questions/14622421/how-to-change-legend-title-in-ggplot

proportion <- teacher_evals_compare |>
  group_by(sen_level, set_level) |>
  count() |>
  group_by(sen_level) |>
  mutate(prop = n / sum(n)) 

ggplot(data = proportion, aes(x = sen_level, y = prop, fill = set_level)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("#154734", "#BD8B13")) + 
  labs(title = "Evaluation of In-Class Activity Use by Instructor Seniority", subtitle = "Conditional Proportion of Sections", x = "Seniority of Instructor", y = "", fill = "SET level")
```

**14. Use `chisq.test()` to carry out a chi-square test of independence between the SET level and instructor seniority level in your new dataset. You will want to look at the documentation and maybe Google a bit!**


```{r}
# code chunk for Q14
chisq.test(x = teacher_evals_compare$set_level, y = teacher_evals_compare$sen_level) 
```

**15. Draw a conclusion about the independence of student evaluation of instructor's use of activities and seniority level based on your chi-square test.**

**Conclusion**

Using an alpha of 0.05, we got a p-value of 0.001299, so we reject the null hypothesis and can conclude that the instructor's use of activities and seniority level are dependent of each other.


### Study Critique

Part of the impetus behind this study was to investigate characteristics of a course or an instructor that might affect student evaluations of teaching that are **not** explicitly related to teaching effectiveness. For instance, it has been shown that gender identity and presentation affect student evaluations of teaching ([an example](https://link.springer.com/article/10.1007/s10755-014-9313-4?nr_email_referer=1)).

**16. If you were to conduct this study at Cal Poly, what are two other variables you would like to collect that you think might be related to student evaluations? These should be course or instructor characteristics that were not collected in this study. Explain what effects you would expect to see for each.**

I think that they should add for students the average amount of hours spent doing work for that class. If they did a lot of work and got a bad grade their opinion will probably be more negative and if it was the opposite their opinion might be more positive regardless of that professor's teaching techniques.And for the second variable maybe the availability of office hours or the amount of students who came to office hours. Usually high numbers indicate how approachable a professor is. And if they have high numbers their ratings will probably tend to be higher as student's are feel safe enough to ask for help and will think highly of their professor as they get to know them more. 
